// person_b_flow.json ã‹ã‚‰æŒ‡å®šãƒãƒ¼ãƒ‰ä»¥é™ã‚’å¾©å…ƒï¼ˆtypeä¿®æ­£è¾¼ã¿ï¼‰
import { createClient } from '@supabase/supabase-js';
import fs from 'fs';
import path from 'path';
import dotenv from 'dotenv';

dotenv.config({ path: path.resolve(__dirname, '../.env.local.bak') });
dotenv.config({ path: path.resolve(__dirname, '../.env.local') });

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
);

const FLOW_ID = '0164502f-0400-49c5-ba09-6705c7349ec2';
const START_NODE_ID = 'quick_reply-1771313825564';
const INPUT_FILE = path.resolve(__dirname, 'person_b_flow.json');

// BFS ã§ä¸‹æµãƒãƒ¼ãƒ‰IDã‚’åé›†
function collectDownstream(startId: string, edges: any[]): Set<string> {
  const visited = new Set<string>();
  const queue = [startId];
  while (queue.length > 0) {
    const id = queue.shift()!;
    if (visited.has(id)) continue;
    visited.add(id);
    for (const e of edges) {
      if (e.source === id && !visited.has(e.target)) queue.push(e.target);
    }
  }
  return visited;
}

async function main() {
  // 1. person_b_flow.json èª­ã¿è¾¼ã¿
  const backup = JSON.parse(fs.readFileSync(INPUT_FILE, 'utf-8'));
  console.log(`ğŸ“‚ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: ${backup.nodes.length} ãƒãƒ¼ãƒ‰, ${backup.edges.length} ã‚¨ãƒƒã‚¸`);

  // 2. ä¸‹æµãƒãƒ¼ãƒ‰IDåé›†
  const downstreamIds = collectDownstream(START_NODE_ID, backup.edges);
  console.log(`ğŸ“Š ${START_NODE_ID} ä»¥é™: ${downstreamIds.size} ãƒãƒ¼ãƒ‰`);

  // 3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã‚µãƒ–ã‚°ãƒ©ãƒ•æŠ½å‡º + typeä¿®æ­£
  const subNodes = backup.nodes
    .filter((n: any) => downstreamIds.has(n.id))
    .map((n: any) => {
      // flowNode â†’ å®Ÿéš›ã®ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã«å¤‰æ›
      if (n.type === 'flowNode' && n.data?.nodeType) {
        return { ...n, type: n.data.nodeType };
      }
      return n;
    });

  const subEdges = backup.edges.filter(
    (e: any) => downstreamIds.has(e.source) && downstreamIds.has(e.target)
  );
  const incomingEdges = backup.edges.filter((e: any) => e.target === START_NODE_ID);

  // typeä¿®æ­£ã®ç¢ºèª
  const typeStats: Record<string, number> = {};
  for (const n of subNodes) {
    typeStats[n.type] = (typeStats[n.type] || 0) + 1;
  }
  console.log('\n  ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—åˆ¥:');
  for (const [t, c] of Object.entries(typeStats)) {
    console.log(`    ${t}: ${c}`);
  }

  // 4. DBå–å¾—
  const { data, error } = await supabase
    .from('chat_flows')
    .select('*')
    .eq('id', FLOW_ID)
    .single();

  if (error || !data) {
    console.error('DBå–å¾—ã‚¨ãƒ©ãƒ¼:', error);
    return;
  }

  const currentDef = data.flow_definition;
  console.log(`\nğŸ¯ DB: ${data.name} | ${currentDef.nodes.length} ãƒãƒ¼ãƒ‰, ${currentDef.edges.length} ã‚¨ãƒƒã‚¸`);

  // 5. ãƒãƒ¼ã‚¸: æ—¢å­˜ã®ã‚µãƒ–ã‚°ãƒ©ãƒ•éƒ¨åˆ†ã‚’é™¤å»ã—ã¦ç½®ãæ›ãˆ
  const filteredNodes = currentDef.nodes.filter((n: any) => !downstreamIds.has(n.id));
  const filteredEdges = currentDef.edges.filter(
    (e: any) => !(downstreamIds.has(e.source) || downstreamIds.has(e.target))
  );

  // å…¥åŠ›ã‚¨ãƒƒã‚¸ï¼ˆå¤–éƒ¨â†’èµ·ç‚¹ï¼‰ã‚’ä¿æŒ
  for (const ie of incomingEdges) {
    if (!filteredEdges.find((e: any) => e.id === ie.id)) {
      filteredEdges.push(ie);
    }
  }

  const mergedNodes = [...filteredNodes, ...subNodes];
  const mergedEdges = [...filteredEdges, ...subEdges];

  console.log(`\nğŸ“Š ãƒãƒ¼ã‚¸çµæœ:`);
  console.log(`  ãƒãƒ¼ãƒ‰: ${currentDef.nodes.length} â†’ ${mergedNodes.length}`);
  console.log(`  ã‚¨ãƒƒã‚¸: ${currentDef.edges.length} â†’ ${mergedEdges.length}`);

  // 6. DBæ›´æ–°
  const mergedDef = { ...currentDef, nodes: mergedNodes, edges: mergedEdges };
  const { error: updateError } = await supabase
    .from('chat_flows')
    .update({
      flow_definition: mergedDef,
      updated_at: new Date().toISOString(),
    })
    .eq('id', FLOW_ID);

  if (updateError) {
    console.error('DBæ›´æ–°ã‚¨ãƒ©ãƒ¼:', updateError);
  } else {
    console.log('\nâœ… å¾©å…ƒå®Œäº†ï¼ãƒ–ãƒ©ã‚¦ã‚¶ã§ â†» ã‚’æŠ¼ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
  }
}

main().catch(console.error);
